{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22d2a66e",
   "metadata": {},
   "source": [
    "## Be careful of the freeze state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4afc3e43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from pretrained_resnet import Pre_trained_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16c0b043",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85b42757",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path = \"/home/b/Desktop/Contrastive/ResNet50_pretrained_imagenet/Saved_models/regressor.pt\"\n",
    "trained_model = torch.load(path)\n",
    "trained_model = trained_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aae18e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.13944223  0.13280212 -0.2124834  -0.15936255 -0.00664011 -0.07304117\n",
      " -0.22576361 -0.07304117 -0.07304117 -0.24568393 -0.19920319 -0.07304117\n",
      "  0.05312085 -0.23904382 -0.07304117 -0.01992032 -0.02656042  0.16600266\n",
      " -0.29216467 -0.30544489 -0.30544489 -0.30544489  0.13944223  0.65073041\n",
      " -0.91633466 -0.50464807 -0.41168659 -0.41168659 -0.41168659 -0.41168659\n",
      " -0.41168659 -0.41168659 -0.05976096  0.43160691 -0.19256308 -0.19256308\n",
      " -0.19256308 -0.19256308 -0.19256308 -0.19256308 -0.19256308 -0.19256308\n",
      " -0.19256308 -0.19256308 -0.37184595 -0.64409031 -0.13280212 -0.11288181\n",
      " -0.09296149 -0.04648074 -0.23904382 -0.27888446 -0.35192563 -0.46480744\n",
      " -0.19920319 -0.28552457 -1.00265604 -1.57370518 -1.68658699 -1.04913679\n",
      " -1.09561753 -0.91633466 -0.19256308 -0.17264276 -0.17928287 -0.15936255\n",
      " -0.07304117 -0.11952191 -0.22576361 -0.01992032 -0.17264276 -0.15936255\n",
      " -0.09296149 -0.02656042  0.          0.1062417   0.19256308 -0.13944223\n",
      " -0.11288181 -0.03984064 -0.04648074 -0.04648074 -0.04648074 -0.04648074\n",
      " -0.04648074 -0.04648074 -0.04648074 -0.04648074 -0.04648074 -0.05312085\n",
      " -0.06640106 -0.05976096 -0.02656042  0.01992032 -0.37848606 -0.11288181\n",
      " -0.23904382 -0.16600266 -0.46480744 -0.19256308]\n"
     ]
    }
   ],
   "source": [
    "# ground truths\n",
    "ground_truths = np.load('/home/b/Desktop/Contrastive/Data/Steering_Angle/val_honda.npz')['val_targets'] \n",
    "print(ground_truths[0:100]) # Rotation angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a82209e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def name_adv(x):\n",
    "    return(float(x.split('/')[-1].split('_')[-1]))\n",
    "\n",
    "def name_combined(x):\n",
    "    return(int(x.split('/')[-1].split('_')[-2]))\n",
    "\n",
    "def name_unseen(x):\n",
    "    return(int(x.split('/')[-1].split('_')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c38fe275",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_folders_combined = sorted(glob.glob('/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_combined/*'), key = name_combined)\n",
    "data_folders_unseen = sorted(glob.glob('/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/*'), key = name_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d00988b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_combined/valHc_combined_1_0',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_combined/valHc_combined_2_0',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_combined/valHc_combined_3_0',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_combined/valHc_combined_4_0',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_combined/valHc_combined_5_0',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_combined/valHc_combined_6_0']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folders_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e73765f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_frost_1',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_zoom_blur_1',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_motion_blur_1',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_snow_1',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_jpeg_compression_1',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_pixelate_1',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_fog_1',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_frost_2',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_zoom_blur_2',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_pixelate_2',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_jpeg_compression_2',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_snow_2',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_fog_2',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_motion_blur_2',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_snow_3',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_fog_3',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_motion_blur_3',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_frost_3',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_zoom_blur_3',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_pixelate_3',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_jpeg_compression_3',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_pixelate_4',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_jpeg_compression_4',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_motion_blur_4',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_snow_4',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_zoom_blur_4',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_frost_4',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_fog_4',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_pixelate_5',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_zoom_blur_5',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_snow_5',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_fog_5',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_motion_blur_5',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_frost_5',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_jpeg_compression_5']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folders_unseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc1ccb87",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_folders_unseen = [\n",
    "    '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_motion_blur_1',\n",
    "    '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_motion_blur_2',\n",
    "    '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_motion_blur_3',\n",
    "    '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_motion_blur_4',\n",
    "    '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_motion_blur_5',\n",
    "    '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_zoom_blur_1',\n",
    "    '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_zoom_blur_2',\n",
    "    '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_zoom_blur_3',\n",
    "    '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_zoom_blur_4',\n",
    "    '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_zoom_blur_5',\n",
    "    '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_pixelate_1',\n",
    "    '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_pixelate_2',\n",
    "    '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_pixelate_3',\n",
    "    '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_pixelate_4',\n",
    "    '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_pixelate_5',\n",
    "    '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_jpeg_compression_1',\n",
    "    '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_jpeg_compression_2',\n",
    "    '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_jpeg_compression_3',\n",
    "    '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_jpeg_compression_4',\n",
    "    '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_jpeg_compression_5',\n",
    "    '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_snow_1',\n",
    "    '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_snow_2',\n",
    "    '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_snow_3',\n",
    "    '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_snow_4',\n",
    "    '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_snow_5',\n",
    "    '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_frost_1',\n",
    "    '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_frost_2',\n",
    "    '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_frost_3',\n",
    "    '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_frost_4',\n",
    "    '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_frost_5',\n",
    "    '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_fog_1',\n",
    "    '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_fog_2',\n",
    "    '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_fog_3',\n",
    "    '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_fog_4',\n",
    "    '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_fog_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd3a2094",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def name_adv_load(x): \n",
    "    return(int(x.split('/')[-1].split('.')[-2]))\n",
    "\n",
    "class DriveDatasetNoLabels(Dataset):\n",
    "    def __init__(self, images):\n",
    "        self.images_list = images\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images_list)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        image_idx = self.images_list[key]\n",
    "        return image_idx.astype(np.float32)\n",
    "    \n",
    "def loss_mse(gt, pred):\n",
    "    # Both in rotation angles, valid_loss = 0.938\n",
    "    mse = torch.mean(torch.Tensor((gt - pred)**2))\n",
    "    return mse\n",
    "\n",
    "def accuracy_metrics(ground_truths, predictions):\n",
    "    error = (ground_truths - predictions)*15.0\n",
    "\n",
    "    acc_1 = 100*(np.sum(np.asarray([ 1.0 if er <=1.5 else 0.0 for er in error]))/error.shape[0])\n",
    "    acc_2 = 100*(np.sum(np.asarray([ 1.0 if er <=3.0 else 0.0 for er in error]))/error.shape[0])\n",
    "    acc_3 = 100*(np.sum(np.asarray([ 1.0 if er <=7.5 else 0.0 for er in error]))/error.shape[0])\n",
    "    acc_4 = 100*(np.sum(np.asarray([ 1.0 if er <=15.0 else 0.0 for er in error]))/error.shape[0])\n",
    "    acc_5 = 100*(np.sum(np.asarray([ 1.0 if er <=30.0 else 0.0 for er in error]))/error.shape[0])\n",
    "    acc_6 = 100*(np.sum(np.asarray([ 1.0 if er <=75.0 else 0.0 for er in error]))/error.shape[0])\n",
    "\n",
    "    mean_acc = (acc_1 + acc_2 + acc_3 + acc_4 + acc_5 + acc_6)/6\n",
    "    return acc_1, acc_2, acc_3, acc_4, acc_5, acc_6, mean_acc   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11d286ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Make predictions from images\n",
    "def make_predictions(all_image_paths,trained_model):\n",
    "    images =[]\n",
    "    #print()\n",
    "    for i in range(len(all_image_paths)):\n",
    "        try: \n",
    "            path = all_image_paths[i]\n",
    "            images.append(np.asarray(Image.open(path)))\n",
    "\n",
    "        except PIL.UnidentifiedImageError:\n",
    "            print(\"Problem!!:\",i)\n",
    "            \n",
    "    images = np.asarray(images)\n",
    "    #print(images.shape)\n",
    "    images = np.moveaxis(images,-1,1)\n",
    "    print(\"Loaded {} images, Max = {}, Min = {}\".format(images.shape, np.max(images), np.min(images)))\n",
    "    \n",
    "    BATCH_SIZE = 1\n",
    "    adv_set = DriveDatasetNoLabels(images)\n",
    "\n",
    "    adv_loader = torch.utils.data.DataLoader(dataset=adv_set,\n",
    "                                                   batch_size=BATCH_SIZE,\n",
    "                                                   collate_fn=None,\n",
    "                                                   shuffle=False)\n",
    "\n",
    "    predictions=[]\n",
    "    with torch.no_grad():\n",
    "        for bi, img in enumerate(adv_loader):\n",
    "            inpt = img.to(device)\n",
    "            outputs = trained_model(inpt) # input should be [1, 3, 66, 200]\n",
    "            predictions.append(outputs.data.item())\n",
    "            \n",
    "    print(\"Predicted {} labels\".format(len(predictions)))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b840a0bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b/.local/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted 10000 labels\n",
      "Acc:\n",
      " 1.5= 82.89999999999999%\n",
      " 3.0= 91.64%\n",
      " 7.5= 96.92%\n",
      " 15 = 98.47%\n",
      " 30= 99.18%\n",
      " 75 = 99.77000000000001%\n",
      "Mean Accuracy = 94.81333333333333%\n",
      "Loss: tensor(0.4060)\n"
     ]
    }
   ],
   "source": [
    "txt_data=[]\n",
    "#predictions on clean\n",
    "clean_paths = sorted(glob.glob('/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_clean/valHc/*.jpg'), key = name_adv_load)\n",
    "#print(clean_path)\n",
    "predictions_clean = make_predictions(clean_paths, trained_model)\n",
    "acc_1, acc_2, acc_3, acc_4, acc_5, acc_6, mean_acc = accuracy_metrics(ground_truths, predictions_clean)\n",
    "print(\"Acc:\\n 1.5= {}%\\n 3.0= {}%\\n 7.5= {}%\\n 15 = {}%\\n 30= {}%\\n 75 = {}%\\nMean Accuracy = {}%\".format(acc_1, \n",
    "                                                                                                   acc_2,\n",
    "                                                                                                   acc_3,\n",
    "                                                                                                   acc_4,\n",
    "                                                                                                   acc_5,\n",
    "                                                                                                   acc_6,\n",
    "                                                                                                   mean_acc))\n",
    "loss = loss_mse(ground_truths, predictions_clean)\n",
    "print(\"Loss:\", loss)\n",
    "txt_data.append(\"Clean:    \" + \"Acc: \" + str(mean_acc) + \"    Loss:\" + str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67403213",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loss_collect = []\n",
    "# acc_collect =[]\n",
    "\n",
    "# predictions_fgsm_total=[]\n",
    "# for i in range(len(data_folders_fgsm)): \n",
    "#     all_image_paths = sorted(glob.glob(data_folders_fgsm[i]+\"/\"+\"*.jpg\"), key = name_adv_load)\n",
    "#     predictions = make_predictions(all_image_paths, trained_model)\n",
    "#     predictions_fgsm_total.append(predictions)\n",
    "    \n",
    "#     acc_1, acc_2, acc_3, acc_4, acc_5, acc_6, mean_acc = accuracy_metrics(ground_truths, predictions)\n",
    "#     print(\"For {}\\nAcc:\\n 1.5= {}%\\n 3.0= {}%\\n 7.5= {}%\\n 15 = {}%\\n 30= {}%\\n 75 = {}%\\nMean Accuracy = {}%\".format(data_folders_fgsm[i].split('/')[-1],\n",
    "#                                                                                                     acc_1, \n",
    "#                                                                                                    acc_2,\n",
    "#                                                                                                    acc_3,\n",
    "#                                                                                                    acc_4,\n",
    "#                                                                                                    acc_5,\n",
    "#                                                                                                    acc_6,\n",
    "#                                                                                                        mean_acc))\n",
    "#     loss = loss_mse(ground_truths, predictions)\n",
    "#     print(\"Loss:\", loss)\n",
    "#     loss_collect.append(str(round(loss.item(),2)))\n",
    "#     acc_collect.append(str(round(mean_acc,2)))\n",
    "#     txt_data.append(str(data_folders_fgsm[i].split('/')[-1]) + \"    \" + \"Acc: \" + str(mean_acc) + \"    Loss:\" + str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d97c81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(\"& {}\\% /{} & {}\\% /{} & {}\\% /{} & {}\\% /{} & {}\\% /{}\".format(acc_collect[0],\n",
    "#                                                                                 loss_collect[0],\n",
    "#                                                                                 acc_collect[1],\n",
    "#                                                                                 loss_collect[1],\n",
    "#                                                                                 acc_collect[2],\n",
    "#                                                                                 loss_collect[2],\n",
    "#                                                                                 acc_collect[3],\n",
    "#                                                                                 loss_collect[3],\n",
    "#                                                                                 acc_collect[4],\n",
    "#                                                                                 loss_collect[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819d4f93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predictions_fgsm_total = np.array(predictions_fgsm_total)\n",
    "# print(predictions_fgsm_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f884edf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# permutation = np.arange(1100,1600,1)\n",
    "# fig, ax = plt.subplots(figsize=(16,5), dpi =150)\n",
    "# ax.plot(ground_truths[permutation]*15.0) \n",
    "# ax.plot(predictions_fgsm_total[4][permutation]*15.0)\n",
    "# ax.set_ylabel(\"Steering Angle (Degrees)\", fontsize=12)\n",
    "# ax.set_xlabel(\"Time Steps\", fontsize=12)\n",
    "# ax.legend([\"Ground Truths\",\"Predictions on FGSM\" ], fontsize=12)\n",
    "# ax.set_ylim([-100,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e729205f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loss_collect = []\n",
    "# acc_collect =[]\n",
    "\n",
    "# predictions_pgd_total=[]\n",
    "# for i in range(len(data_folders_pgd)): \n",
    "#     all_image_paths = sorted(glob.glob(data_folders_pgd[i]+\"/\"+\"*.jpg\"), key = name_adv_load)\n",
    "#     predictions = make_predictions(all_image_paths, trained_model)\n",
    "#     predictions_pgd_total.append(predictions)\n",
    "    \n",
    "#     acc_1, acc_2, acc_3, acc_4, acc_5, acc_6, mean_acc = accuracy_metrics(ground_truths, predictions)\n",
    "#     print(\"For {}\\nAcc:\\n 1.5= {}%\\n 3.0= {}%\\n 7.5= {}%\\n 15 = {}%\\n 30= {}%\\n 75 = {}%\\nMean Accuracy = {}%\".format(data_folders_pgd[i].split('/')[-1],\n",
    "#                                                                                                     acc_1, \n",
    "#                                                                                                    acc_2,\n",
    "#                                                                                                    acc_3,\n",
    "#                                                                                                    acc_4,\n",
    "#                                                                                                    acc_5,\n",
    "#                                                                                                    acc_6,\n",
    "#                                                                                                    mean_acc))\n",
    "#     loss = loss_mse(ground_truths, predictions)\n",
    "#     print(\"Loss:\", loss)\n",
    "#     loss_collect.append(str(round(loss.item(),2)))\n",
    "#     acc_collect.append(str(round(mean_acc,2)))\n",
    "#     txt_data.append(str(data_folders_pgd[i].split('/')[-1]) + \"    \" + \"Acc: \" + str(mean_acc) + \"    Loss:\" + str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff05f49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(\"& {}\\% /{} & {}\\% /{} & {}\\% /{} & {}\\% /{} & {}\\% /{}\".format(acc_collect[0],\n",
    "#                                                                                 loss_collect[0],\n",
    "#                                                                                 acc_collect[1],\n",
    "#                                                                                 loss_collect[1],\n",
    "#                                                                                 acc_collect[2],\n",
    "#                                                                                 loss_collect[2],\n",
    "#                                                                                 acc_collect[3],\n",
    "#                                                                                 loss_collect[3],\n",
    "#                                                                                 acc_collect[4],\n",
    "#                                                                                 loss_collect[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443a7bc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predictions_pgd_total = np.array(predictions_pgd_total)\n",
    "# print(predictions_pgd_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9727ce1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# permutation = np.arange(900,1600,1)\n",
    "# fig, ax = plt.subplots(figsize=(16,5), dpi =150)\n",
    "# ax.plot(ground_truths[permutation]*15.0) \n",
    "# ax.plot(predictions_pgd_total[4][permutation]*15.0)\n",
    "# ax.set_ylabel(\"Steering Angle (Degrees)\", fontsize=14)\n",
    "# ax.set_xlabel(\"Time Steps\",fontsize=14)\n",
    "# ax.legend([\"Ground Truths\",\"Predictions on FGSM\" ],fontsize=14)\n",
    "# ax.set_ylim([-100,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2794a85",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded (10000, 3, 66, 200) images, Max = 172, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valHc_combined_1_0\n",
      "Acc:\n",
      " 1.5= 83.89999999999999%\n",
      " 3.0= 86.78%\n",
      " 7.5= 91.58%\n",
      " 15 = 94.43%\n",
      " 30= 96.47%\n",
      " 75 = 98.14%\n",
      "Mean Accuracy = 91.88333333333333%\n",
      "Loss: tensor(8.4749)\n",
      "\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valHc_combined_2_0\n",
      "Acc:\n",
      " 1.5= 50.5%\n",
      " 3.0= 59.75%\n",
      " 7.5= 80.66%\n",
      " 15 = 90.68%\n",
      " 30= 95.19999999999999%\n",
      " 75 = 97.67%\n",
      "Mean Accuracy = 79.07666666666667%\n",
      "Loss: tensor(8.3673)\n",
      "\n",
      "Loaded (10000, 3, 66, 200) images, Max = 226, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valHc_combined_3_0\n",
      "Acc:\n",
      " 1.5= 45.59%\n",
      " 3.0= 56.75%\n",
      " 7.5= 80.42%\n",
      " 15 = 90.60000000000001%\n",
      " 30= 95.48%\n",
      " 75 = 97.7%\n",
      "Mean Accuracy = 77.75666666666667%\n",
      "Loss: tensor(8.2444)\n",
      "\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valHc_combined_4_0\n",
      "Acc:\n",
      " 1.5= 30.29%\n",
      " 3.0= 38.42%\n",
      " 7.5= 65.64%\n",
      " 15 = 88.86%\n",
      " 30= 95.21%\n",
      " 75 = 97.67%\n",
      "Mean Accuracy = 69.34833333333334%\n",
      "Loss: tensor(8.4318)\n",
      "\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valHc_combined_5_0\n",
      "Acc:\n",
      " 1.5= 59.98%\n",
      " 3.0= 71.28999999999999%\n",
      " 7.5= 87.01%\n",
      " 15 = 93.16%\n",
      " 30= 96.36%\n",
      " 75 = 97.92999999999999%\n",
      "Mean Accuracy = 84.28833333333333%\n",
      "Loss: tensor(7.2836)\n",
      "\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valHc_combined_6_0\n",
      "Acc:\n",
      " 1.5= 33.269999999999996%\n",
      " 3.0= 42.67%\n",
      " 7.5= 69.54%\n",
      " 15 = 87.86%\n",
      " 30= 94.87%\n",
      " 75 = 97.57000000000001%\n",
      "Mean Accuracy = 70.96333333333334%\n",
      "Loss: tensor(8.4857)\n"
     ]
    }
   ],
   "source": [
    "loss_collect = []\n",
    "acc_collect =[]\n",
    "predictions_combined_total=[]\n",
    "for i in range(len(data_folders_combined)): \n",
    "    all_image_paths = sorted(glob.glob(data_folders_combined[i]+\"/\"+\"*.jpg\"), key = name_adv_load)\n",
    "    predictions = make_predictions(all_image_paths, trained_model)\n",
    "    predictions_combined_total.append(predictions)\n",
    "    \n",
    "    acc_1, acc_2, acc_3, acc_4, acc_5, acc_6, mean_acc = accuracy_metrics(ground_truths, predictions)\n",
    "    print(\"For {}\\nAcc:\\n 1.5= {}%\\n 3.0= {}%\\n 7.5= {}%\\n 15 = {}%\\n 30= {}%\\n 75 = {}%\\nMean Accuracy = {}%\".format(data_folders_combined[i].split('/')[-1],\n",
    "                                                                                                    acc_1, \n",
    "                                                                                                   acc_2,\n",
    "                                                                                                   acc_3,\n",
    "                                                                                                   acc_4,\n",
    "                                                                                                   acc_5,\n",
    "                                                                                                   acc_6,\n",
    "                                                                                                   mean_acc))\n",
    "    loss = loss_mse(ground_truths, predictions)\n",
    "    print(\"Loss:\", loss)\n",
    "    loss_collect.append(str(round(loss.item(),2)))\n",
    "    acc_collect.append(str(round(mean_acc,2)))\n",
    "    txt_data.append(str(data_folders_combined[i].split('/')[-1]) + \"    \" + \"Acc: \" + str(mean_acc) + \"    Loss:\" + str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efc497f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "& 91.88\\% /8.47 & 79.08\\% /8.37 & 77.76\\% /8.24 & 69.35\\% /8.43 & 84.29\\% /7.28 & 70.96\\% /8.49\n"
     ]
    }
   ],
   "source": [
    "print(\"& {}\\% /{} & {}\\% /{} & {}\\% /{} & {}\\% /{} & {}\\% /{} & {}\\% /{}\".format(acc_collect[0],\n",
    "                                                                                loss_collect[0],\n",
    "                                                                                acc_collect[1],\n",
    "                                                                                loss_collect[1],\n",
    "                                                                                acc_collect[2],\n",
    "                                                                                loss_collect[2],\n",
    "                                                                                acc_collect[3],\n",
    "                                                                                loss_collect[3],\n",
    "                                                                                acc_collect[4],\n",
    "                                                                                loss_collect[4],\n",
    "                                                                                acc_collect[5],\n",
    "                                                                                loss_collect[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5047bfe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valB_IMGC_motion_blur_1\n",
      "Acc:\n",
      " 1.5= 71.78%\n",
      " 3.0= 84.86%\n",
      " 7.5= 94.66%\n",
      " 15 = 97.35000000000001%\n",
      " 30= 98.66%\n",
      " 75 = 99.52%\n",
      "Mean Accuracy = 91.13833333333332%\n",
      "Loss: tensor(1.0141)\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valB_IMGC_motion_blur_2\n",
      "Acc:\n",
      " 1.5= 67.78999999999999%\n",
      " 3.0= 81.39999999999999%\n",
      " 7.5= 93.01%\n",
      " 15 = 96.32%\n",
      " 30= 98.16%\n",
      " 75 = 99.39%\n",
      "Mean Accuracy = 89.34499999999998%\n",
      "Loss: tensor(1.5025)\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valB_IMGC_motion_blur_3\n",
      "Acc:\n",
      " 1.5= 64.05%\n",
      " 3.0= 76.98%\n",
      " 7.5= 90.59%\n",
      " 15 = 95.24000000000001%\n",
      " 30= 97.23%\n",
      " 75 = 98.92%\n",
      "Mean Accuracy = 87.16833333333334%\n",
      "Loss: tensor(3.0233)\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valB_IMGC_motion_blur_4\n",
      "Acc:\n",
      " 1.5= 58.989999999999995%\n",
      " 3.0= 71.05%\n",
      " 7.5= 86.96000000000001%\n",
      " 15 = 93.5%\n",
      " 30= 96.39999999999999%\n",
      " 75 = 98.61999999999999%\n",
      "Mean Accuracy = 84.25333333333333%\n",
      "Loss: tensor(4.1727)\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valB_IMGC_motion_blur_5\n",
      "Acc:\n",
      " 1.5= 55.169999999999995%\n",
      " 3.0= 66.66%\n",
      " 7.5= 84.17999999999999%\n",
      " 15 = 92.06%\n",
      " 30= 95.83%\n",
      " 75 = 98.35000000000001%\n",
      "Mean Accuracy = 82.04166666666667%\n",
      "Loss: tensor(5.2076)\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valB_IMGC_zoom_blur_1\n",
      "Acc:\n",
      " 1.5= 64.24%\n",
      " 3.0= 78.12%\n",
      " 7.5= 90.71000000000001%\n",
      " 15 = 95.12%\n",
      " 30= 97.47%\n",
      " 75 = 98.85000000000001%\n",
      "Mean Accuracy = 87.41833333333335%\n",
      "Loss: tensor(3.6172)\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valB_IMGC_zoom_blur_2\n",
      "Acc:\n",
      " 1.5= 61.21%\n",
      " 3.0= 74.36%\n",
      " 7.5= 89.01%\n",
      " 15 = 94.25%\n",
      " 30= 96.75%\n",
      " 75 = 98.56%\n",
      "Mean Accuracy = 85.69%\n",
      "Loss: tensor(5.1082)\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valB_IMGC_zoom_blur_3\n",
      "Acc:\n",
      " 1.5= 56.32%\n",
      " 3.0= 70.00999999999999%\n",
      " 7.5= 86.71%\n",
      " 15 = 93.36%\n",
      " 30= 96.34%\n",
      " 75 = 98.2%\n",
      "Mean Accuracy = 83.49%\n",
      "Loss: tensor(6.2584)\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valB_IMGC_zoom_blur_4\n",
      "Acc:\n",
      " 1.5= 54.730000000000004%\n",
      " 3.0= 68.57%\n",
      " 7.5= 85.99%\n",
      " 15 = 92.72%\n",
      " 30= 96.09%\n",
      " 75 = 98.09%\n",
      "Mean Accuracy = 82.69833333333334%\n",
      "Loss: tensor(6.9026)\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valB_IMGC_zoom_blur_5\n",
      "Acc:\n",
      " 1.5= 53.18000000000001%\n",
      " 3.0= 66.46%\n",
      " 7.5= 84.91%\n",
      " 15 = 92.22%\n",
      " 30= 95.95%\n",
      " 75 = 97.97%\n",
      "Mean Accuracy = 81.78166666666665%\n",
      "Loss: tensor(7.1876)\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valB_IMGC_pixelate_1\n",
      "Acc:\n",
      " 1.5= 76.28%\n",
      " 3.0= 88.08%\n",
      " 7.5= 95.54%\n",
      " 15 = 97.77%\n",
      " 30= 98.87%\n",
      " 75 = 99.68%\n",
      "Mean Accuracy = 92.70333333333333%\n",
      "Loss: tensor(0.6168)\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valB_IMGC_pixelate_2\n",
      "Acc:\n",
      " 1.5= 76.31%\n",
      " 3.0= 87.94999999999999%\n",
      " 7.5= 95.54%\n",
      " 15 = 97.77%\n",
      " 30= 98.8%\n",
      " 75 = 99.69%\n",
      "Mean Accuracy = 92.67666666666666%\n",
      "Loss: tensor(0.6466)\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valB_IMGC_pixelate_3\n",
      "Acc:\n",
      " 1.5= 74.39%\n",
      " 3.0= 86.85000000000001%\n",
      " 7.5= 95.19%\n",
      " 15 = 97.61999999999999%\n",
      " 30= 98.75%\n",
      " 75 = 99.66000000000001%\n",
      "Mean Accuracy = 92.07666666666667%\n",
      "Loss: tensor(0.6917)\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valB_IMGC_pixelate_4\n",
      "Acc:\n",
      " 1.5= 74.05000000000001%\n",
      " 3.0= 86.53%\n",
      " 7.5= 94.98%\n",
      " 15 = 97.43%\n",
      " 30= 98.7%\n",
      " 75 = 99.59%\n",
      "Mean Accuracy = 91.88%\n",
      "Loss: tensor(0.8309)\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valB_IMGC_pixelate_5\n",
      "Acc:\n",
      " 1.5= 73.45%\n",
      " 3.0= 86.36%\n",
      " 7.5= 94.78999999999999%\n",
      " 15 = 97.28999999999999%\n",
      " 30= 98.59%\n",
      " 75 = 99.58%\n",
      "Mean Accuracy = 91.67666666666668%\n",
      "Loss: tensor(0.9148)\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valB_IMGC_jpeg_compression_1\n",
      "Acc:\n",
      " 1.5= 74.58%\n",
      " 3.0= 86.53999999999999%\n",
      " 7.5= 95.03%\n",
      " 15 = 97.58%\n",
      " 30= 98.72999999999999%\n",
      " 75 = 99.68%\n",
      "Mean Accuracy = 92.02333333333331%\n",
      "Loss: tensor(0.7189)\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valB_IMGC_jpeg_compression_2\n",
      "Acc:\n",
      " 1.5= 72.99%\n",
      " 3.0= 85.34%\n",
      " 7.5= 94.6%\n",
      " 15 = 97.17%\n",
      " 30= 98.55000000000001%\n",
      " 75 = 99.55000000000001%\n",
      "Mean Accuracy = 91.36666666666667%\n",
      "Loss: tensor(0.8905)\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valB_IMGC_jpeg_compression_3\n",
      "Acc:\n",
      " 1.5= 71.99%\n",
      " 3.0= 84.68%\n",
      " 7.5= 94.28999999999999%\n",
      " 15 = 97.07000000000001%\n",
      " 30= 98.5%\n",
      " 75 = 99.59%\n",
      "Mean Accuracy = 91.02%\n",
      "Loss: tensor(0.9962)\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valB_IMGC_jpeg_compression_4\n",
      "Acc:\n",
      " 1.5= 69.88%\n",
      " 3.0= 81.89%\n",
      " 7.5= 92.85%\n",
      " 15 = 96.41999999999999%\n",
      " 30= 98.21%\n",
      " 75 = 99.29%\n",
      "Mean Accuracy = 89.75666666666666%\n",
      "Loss: tensor(1.4970)\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valB_IMGC_jpeg_compression_5\n",
      "Acc:\n",
      " 1.5= 67.71000000000001%\n",
      " 3.0= 79.74%\n",
      " 7.5= 90.89%\n",
      " 15 = 95.42%\n",
      " 30= 97.61%\n",
      " 75 = 99.02%\n",
      "Mean Accuracy = 88.39833333333333%\n",
      "Loss: tensor(2.1595)\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valB_IMGC_snow_1\n",
      "Acc:\n",
      " 1.5= 71.14%\n",
      " 3.0= 79.38%\n",
      " 7.5= 89.97%\n",
      " 15 = 94.66%\n",
      " 30= 97.09%\n",
      " 75 = 98.63%\n",
      "Mean Accuracy = 88.47833333333334%\n",
      "Loss: tensor(4.6748)\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 15\n",
      "Predicted 10000 labels\n",
      "For valB_IMGC_snow_2\n",
      "Acc:\n",
      " 1.5= 69.69999999999999%\n",
      " 3.0= 77.14999999999999%\n",
      " 7.5= 87.48%\n",
      " 15 = 93.17%\n",
      " 30= 96.22%\n",
      " 75 = 98.22999999999999%\n",
      "Mean Accuracy = 86.99166666666667%\n",
      "Loss: tensor(6.9721)\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 13\n",
      "Predicted 10000 labels\n",
      "For valB_IMGC_snow_3\n",
      "Acc:\n",
      " 1.5= 63.85999999999999%\n",
      " 3.0= 72.7%\n",
      " 7.5= 85.15%\n",
      " 15 = 91.85%\n",
      " 30= 95.64%\n",
      " 75 = 97.92999999999999%\n",
      "Mean Accuracy = 84.52166666666666%\n",
      "Loss: tensor(7.7121)\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 19\n",
      "Predicted 10000 labels\n",
      "For valB_IMGC_snow_4\n",
      "Acc:\n",
      " 1.5= 63.62%\n",
      " 3.0= 71.38%\n",
      " 7.5= 83.35000000000001%\n",
      " 15 = 90.29%\n",
      " 30= 94.73%\n",
      " 75 = 97.54%\n",
      "Mean Accuracy = 83.48500000000001%\n",
      "Loss: tensor(8.1489)\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 37\n",
      "Predicted 10000 labels\n",
      "For valB_IMGC_snow_5\n",
      "Acc:\n",
      " 1.5= 45.7%\n",
      " 3.0= 54.97%\n",
      " 7.5= 73.78%\n",
      " 15 = 86.49%\n",
      " 30= 93.62%\n",
      " 75 = 97.54%\n",
      "Mean Accuracy = 75.35000000000001%\n",
      "Loss: tensor(8.2404)\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valB_IMGC_frost_1\n",
      "Acc:\n",
      " 1.5= 58.230000000000004%\n",
      " 3.0= 69.85%\n",
      " 7.5= 85.88%\n",
      " 15 = 93.07%\n",
      " 30= 96.6%\n",
      " 75 = 98.75%\n",
      "Mean Accuracy = 83.73%\n",
      "Loss: tensor(3.1823)\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valB_IMGC_frost_2\n",
      "Acc:\n",
      " 1.5= 52.88%\n",
      " 3.0= 61.62%\n",
      " 7.5= 77.12%\n",
      " 15 = 87.0%\n",
      " 30= 93.5%\n",
      " 75 = 97.72%\n",
      "Mean Accuracy = 78.30666666666667%\n",
      "Loss: tensor(6.7594)\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 2\n",
      "Predicted 10000 labels\n",
      "For valB_IMGC_frost_3\n",
      "Acc:\n",
      " 1.5= 51.01%\n",
      " 3.0= 58.19%\n",
      " 7.5= 72.25%\n",
      " 15 = 83.14%\n",
      " 30= 91.10000000000001%\n",
      " 75 = 97.14%\n",
      "Mean Accuracy = 75.47166666666666%\n",
      "Loss: tensor(7.9668)\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 4\n",
      "Predicted 10000 labels\n",
      "For valB_IMGC_frost_4\n",
      "Acc:\n",
      " 1.5= 53.010000000000005%\n",
      " 3.0= 60.23%\n",
      " 7.5= 74.2%\n",
      " 15 = 84.08%\n",
      " 30= 91.36999999999999%\n",
      " 75 = 97.27%\n",
      "Mean Accuracy = 76.69333333333333%\n",
      "Loss: tensor(8.8323)\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 4\n",
      "Predicted 10000 labels\n",
      "For valB_IMGC_frost_5\n",
      "Acc:\n",
      " 1.5= 52.78%\n",
      " 3.0= 58.81999999999999%\n",
      " 7.5= 72.03%\n",
      " 15 = 82.15%\n",
      " 30= 90.10000000000001%\n",
      " 75 = 96.88%\n",
      "Mean Accuracy = 75.46%\n",
      "Loss: tensor(9.4572)\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valB_IMGC_fog_1\n",
      "Acc:\n",
      " 1.5= 47.72%\n",
      " 3.0= 58.209999999999994%\n",
      " 7.5= 76.64999999999999%\n",
      " 15 = 86.63%\n",
      " 30= 93.26%\n",
      " 75 = 97.66%\n",
      "Mean Accuracy = 76.68833333333333%\n",
      "Loss: tensor(7.4889)\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valB_IMGC_fog_2\n",
      "Acc:\n",
      " 1.5= 46.64%\n",
      " 3.0= 56.06%\n",
      " 7.5= 73.45%\n",
      " 15 = 85.57000000000001%\n",
      " 30= 92.44%\n",
      " 75 = 97.19%\n",
      "Mean Accuracy = 75.22500000000001%\n",
      "Loss: tensor(7.7887)\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted 10000 labels\n",
      "For valB_IMGC_fog_3\n",
      "Acc:\n",
      " 1.5= 44.39%\n",
      " 3.0= 52.96999999999999%\n",
      " 7.5= 69.69999999999999%\n",
      " 15 = 82.66%\n",
      " 30= 91.64999999999999%\n",
      " 75 = 97.15%\n",
      "Mean Accuracy = 73.08666666666666%\n",
      "Loss: tensor(8.8199)\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valB_IMGC_fog_4\n",
      "Acc:\n",
      " 1.5= 41.47%\n",
      " 3.0= 50.019999999999996%\n",
      " 7.5= 69.05%\n",
      " 15 = 82.35%\n",
      " 30= 91.72%\n",
      " 75 = 97.17%\n",
      "Mean Accuracy = 71.96333333333334%\n",
      "Loss: tensor(8.7192)\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valB_IMGC_fog_5\n",
      "Acc:\n",
      " 1.5= 46.67%\n",
      " 3.0= 54.37%\n",
      " 7.5= 71.98%\n",
      " 15 = 84.21%\n",
      " 30= 92.10000000000001%\n",
      " 75 = 97.06%\n",
      "Mean Accuracy = 74.39833333333333%\n",
      "Loss: tensor(9.0965)\n"
     ]
    }
   ],
   "source": [
    "loss_collect = []\n",
    "acc_collect =[]\n",
    "predictions_unseen_total=[]\n",
    "for i in range(len(data_folders_unseen)): \n",
    "    all_image_paths = sorted(glob.glob(data_folders_unseen[i]+\"/\"+\"*.jpg\"), key = name_adv_load)\n",
    "    predictions = make_predictions(all_image_paths, trained_model)\n",
    "    predictions_unseen_total.append(predictions)\n",
    "    \n",
    "    acc_1, acc_2, acc_3, acc_4, acc_5, acc_6, mean_acc = accuracy_metrics(ground_truths, predictions)\n",
    "    print(\"For {}\\nAcc:\\n 1.5= {}%\\n 3.0= {}%\\n 7.5= {}%\\n 15 = {}%\\n 30= {}%\\n 75 = {}%\\nMean Accuracy = {}%\".format(data_folders_unseen[i].split('/')[-1],\n",
    "                                                                                                    acc_1, \n",
    "                                                                                                   acc_2,\n",
    "                                                                                                   acc_3,\n",
    "                                                                                                   acc_4,\n",
    "                                                                                                   acc_5,\n",
    "                                                                                                   acc_6,\n",
    "                                                                                                   mean_acc))\n",
    "    loss = loss_mse(ground_truths, predictions)\n",
    "    print(\"Loss:\", loss)\n",
    "    loss_collect.append(str(round(loss.item(),2)))\n",
    "    acc_collect.append(str(round(mean_acc,2)))\n",
    "    txt_data.append(str(data_folders_unseen[i].split('/')[-1]) + \"    \" + \"Acc: \" + str(mean_acc) + \"    Loss:\" + str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e26708b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4\n",
      "5\n",
      "& 91.14\\% /1.01 & 89.34\\% /1.5 & 87.17\\% /3.02 & 84.25\\% /4.17 & 82.04\\% /5.21\n",
      "\n",
      "5 6 7 8 9\n",
      "10\n",
      "& 87.42\\% /3.62 & 85.69\\% /5.11 & 83.49\\% /6.26 & 82.7\\% /6.9 & 81.78\\% /7.19\n",
      "\n",
      "10 11 12 13 14\n",
      "15\n",
      "& 92.7\\% /0.62 & 92.68\\% /0.65 & 92.08\\% /0.69 & 91.88\\% /0.83 & 91.68\\% /0.91\n",
      "\n",
      "15 16 17 18 19\n",
      "20\n",
      "& 92.02\\% /0.72 & 91.37\\% /0.89 & 91.02\\% /1.0 & 89.76\\% /1.5 & 88.4\\% /2.16\n",
      "\n",
      "20 21 22 23 24\n",
      "25\n",
      "& 88.48\\% /4.67 & 86.99\\% /6.97 & 84.52\\% /7.71 & 83.49\\% /8.15 & 75.35\\% /8.24\n",
      "\n",
      "25 26 27 28 29\n",
      "30\n",
      "& 83.73\\% /3.18 & 78.31\\% /6.76 & 75.47\\% /7.97 & 76.69\\% /8.83 & 75.46\\% /9.46\n",
      "\n",
      "30 31 32 33 34\n",
      "35\n",
      "& 76.69\\% /7.49 & 75.23\\% /7.79 & 73.09\\% /8.82 & 71.96\\% /8.72 & 74.4\\% /9.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for j in range(1,len(data_folders_unseen)+1):\n",
    "    if j%5==0:\n",
    "        \n",
    "        print(j-5, j-4, j-3, j-2, j-1)\n",
    "        print(j)\n",
    "#         print(data_folders_unseen[j])\n",
    "        print(\"& {}\\% /{} & {}\\% /{} & {}\\% /{} & {}\\% /{} & {}\\% /{}\\n\".format(acc_collect[j-5],\n",
    "                                                                                        loss_collect[j-5],\n",
    "                                                                                        acc_collect[j-4],\n",
    "                                                                                        loss_collect[j-4],\n",
    "                                                                                        acc_collect[j-3],\n",
    "                                                                                        loss_collect[j-3],\n",
    "                                                                                        acc_collect[j-2],\n",
    "                                                                                        loss_collect[j-2],\n",
    "                                                                                        acc_collect[j-1],\n",
    "                                                                                        loss_collect[j-1]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9c8b4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(data_folders_unseen))\n",
    "print(data_folders_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4cfb0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fname= \"/home/b/Desktop/week_3_experiments/results/\" + path.split('/')[-1] + \"_results.txt\"\n",
    "# np.savetxt(fname, txt_data, fmt='%s', newline='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a988c8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852ca748",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
