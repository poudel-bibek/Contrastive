{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c902c0ef",
   "metadata": {},
   "source": [
    "## Be careful of the freeze state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2c34473",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from pretrained_resnet import Pre_trained_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16c0b043",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85b42757",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path = \"/home/b/Desktop/Contrastive/ResNet50_pretrained_imagenet/Saved_models/regressor.pt\"\n",
    "trained_model = torch.load(path)\n",
    "trained_model = trained_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aae18e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.13944223  0.13280212 -0.2124834  -0.15936255 -0.00664011 -0.07304117\n",
      " -0.22576361 -0.07304117 -0.07304117 -0.24568393 -0.19920319 -0.07304117\n",
      "  0.05312085 -0.23904382 -0.07304117 -0.01992032 -0.02656042  0.16600266\n",
      " -0.29216467 -0.30544489 -0.30544489 -0.30544489  0.13944223  0.65073041\n",
      " -0.91633466 -0.50464807 -0.41168659 -0.41168659 -0.41168659 -0.41168659\n",
      " -0.41168659 -0.41168659 -0.05976096  0.43160691 -0.19256308 -0.19256308\n",
      " -0.19256308 -0.19256308 -0.19256308 -0.19256308 -0.19256308 -0.19256308\n",
      " -0.19256308 -0.19256308 -0.37184595 -0.64409031 -0.13280212 -0.11288181\n",
      " -0.09296149 -0.04648074 -0.23904382 -0.27888446 -0.35192563 -0.46480744\n",
      " -0.19920319 -0.28552457 -1.00265604 -1.57370518 -1.68658699 -1.04913679\n",
      " -1.09561753 -0.91633466 -0.19256308 -0.17264276 -0.17928287 -0.15936255\n",
      " -0.07304117 -0.11952191 -0.22576361 -0.01992032 -0.17264276 -0.15936255\n",
      " -0.09296149 -0.02656042  0.          0.1062417   0.19256308 -0.13944223\n",
      " -0.11288181 -0.03984064 -0.04648074 -0.04648074 -0.04648074 -0.04648074\n",
      " -0.04648074 -0.04648074 -0.04648074 -0.04648074 -0.04648074 -0.05312085\n",
      " -0.06640106 -0.05976096 -0.02656042  0.01992032 -0.37848606 -0.11288181\n",
      " -0.23904382 -0.16600266 -0.46480744 -0.19256308]\n"
     ]
    }
   ],
   "source": [
    "# ground truths\n",
    "ground_truths = np.load('/home/b/Desktop/Contrastive/Data/Steering_Angle/val_honda.npz')['val_targets'] \n",
    "print(ground_truths[0:100]) # Rotation angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a82209e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def name_adv(x):\n",
    "    return(float(x.split('/')[-1].split('_')[-1]))\n",
    "\n",
    "def name_combined(x):\n",
    "    return(int(x.split('/')[-1].split('_')[-2]))\n",
    "\n",
    "def name_unseen(x):\n",
    "    return(int(x.split('/')[-1].split('_')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c38fe275",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_folders_combined = sorted(glob.glob('/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_combined/*'), key = name_combined)\n",
    "data_folders_unseen = sorted(glob.glob('/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/*'), key = name_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d00988b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_combined/valHc_combined_1_0',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_combined/valHc_combined_2_0',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_combined/valHc_combined_3_0',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_combined/valHc_combined_4_0',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_combined/valHc_combined_5_0',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_combined/valHc_combined_6_0']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folders_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e73765f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_frost_1',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_zoom_blur_1',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_motion_blur_1',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_snow_1',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_jpeg_compression_1',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_pixelate_1',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_fog_1',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_frost_2',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_zoom_blur_2',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_pixelate_2',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_jpeg_compression_2',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_snow_2',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_fog_2',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_motion_blur_2',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_snow_3',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_fog_3',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_motion_blur_3',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_frost_3',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_zoom_blur_3',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_pixelate_3',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_jpeg_compression_3',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_pixelate_4',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_jpeg_compression_4',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_motion_blur_4',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_snow_4',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_zoom_blur_4',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_frost_4',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_fog_4',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_pixelate_5',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_zoom_blur_5',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_snow_5',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_fog_5',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_motion_blur_5',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_frost_5',\n",
       " '/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_unseen/valB_IMGC_jpeg_compression_5']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folders_unseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc1ccb87",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_folders_unseen = [\n",
    "    './test_Data/validation_sets_unseen/valB_IMGC_motion_blur_1',\n",
    "    './test_Data/validation_sets_unseen/valB_IMGC_motion_blur_2',\n",
    "    './test_Data/validation_sets_unseen/valB_IMGC_motion_blur_3',\n",
    "    './test_Data/validation_sets_unseen/valB_IMGC_motion_blur_4',\n",
    "    './test_Data/validation_sets_unseen/valB_IMGC_motion_blur_5',\n",
    "    './test_Data/validation_sets_unseen/valB_IMGC_zoom_blur_1',\n",
    "    './test_Data/validation_sets_unseen/valB_IMGC_zoom_blur_2',\n",
    "    './test_Data/validation_sets_unseen/valB_IMGC_zoom_blur_3',\n",
    "    './test_Data/validation_sets_unseen/valB_IMGC_zoom_blur_4',\n",
    "    './test_Data/validation_sets_unseen/valB_IMGC_zoom_blur_5',\n",
    "    './test_Data/validation_sets_unseen/valB_IMGC_pixelate_1',\n",
    "    './test_Data/validation_sets_unseen/valB_IMGC_pixelate_2',\n",
    "    './test_Data/validation_sets_unseen/valB_IMGC_pixelate_3',\n",
    "    './test_Data/validation_sets_unseen/valB_IMGC_pixelate_4',\n",
    "    './test_Data/validation_sets_unseen/valB_IMGC_pixelate_5',\n",
    "    './test_Data/validation_sets_unseen/valB_IMGC_jpeg_compression_1',\n",
    "    './test_Data/validation_sets_unseen/valB_IMGC_jpeg_compression_2',\n",
    "    './test_Data/validation_sets_unseen/valB_IMGC_jpeg_compression_3',\n",
    "    './test_Data/validation_sets_unseen/valB_IMGC_jpeg_compression_4',\n",
    "    './test_Data/validation_sets_unseen/valB_IMGC_jpeg_compression_5',\n",
    "    './test_Data/validation_sets_unseen/valB_IMGC_snow_1',\n",
    "    './test_Data/validation_sets_unseen/valB_IMGC_snow_2',\n",
    "    './test_Data/validation_sets_unseen/valB_IMGC_snow_3',\n",
    "    './test_Data/validation_sets_unseen/valB_IMGC_snow_4',\n",
    "    './test_Data/validation_sets_unseen/valB_IMGC_snow_5',\n",
    "    './test_Data/validation_sets_unseen/valB_IMGC_frost_1',\n",
    "    './test_Data/validation_sets_unseen/valB_IMGC_frost_2',\n",
    "    './test_Data/validation_sets_unseen/valB_IMGC_frost_3',\n",
    "    './test_Data/validation_sets_unseen/valB_IMGC_frost_4',\n",
    "    './test_Data/validation_sets_unseen/valB_IMGC_frost_5',\n",
    "    './test_Data/validation_sets_unseen/valB_IMGC_fog_1',\n",
    "    './test_Data/validation_sets_unseen/valB_IMGC_fog_2',\n",
    "    './test_Data/validation_sets_unseen/valB_IMGC_fog_3',\n",
    "    './test_Data/validation_sets_unseen/valB_IMGC_fog_4',\n",
    "    './test_Data/validation_sets_unseen/valB_IMGC_fog_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd3a2094",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def name_adv_load(x): \n",
    "    return(int(x.split('/')[-1].split('.')[-2]))\n",
    "\n",
    "class DriveDatasetNoLabels(Dataset):\n",
    "    def __init__(self, images):\n",
    "        self.images_list = images\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images_list)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        image_idx = self.images_list[key]\n",
    "        return image_idx.astype(np.float32)\n",
    "    \n",
    "def loss_mse(gt, pred):\n",
    "    # Both in rotation angles, valid_loss = 0.938\n",
    "    mse = torch.mean(torch.Tensor((gt - pred)**2))\n",
    "    return mse\n",
    "\n",
    "def accuracy_metrics(ground_truths, predictions):\n",
    "    error = (ground_truths - predictions)*15.0\n",
    "\n",
    "    acc_1 = 100*(np.sum(np.asarray([ 1.0 if er <=1.5 else 0.0 for er in error]))/error.shape[0])\n",
    "    acc_2 = 100*(np.sum(np.asarray([ 1.0 if er <=3.0 else 0.0 for er in error]))/error.shape[0])\n",
    "    acc_3 = 100*(np.sum(np.asarray([ 1.0 if er <=7.5 else 0.0 for er in error]))/error.shape[0])\n",
    "    acc_4 = 100*(np.sum(np.asarray([ 1.0 if er <=15.0 else 0.0 for er in error]))/error.shape[0])\n",
    "    acc_5 = 100*(np.sum(np.asarray([ 1.0 if er <=30.0 else 0.0 for er in error]))/error.shape[0])\n",
    "    acc_6 = 100*(np.sum(np.asarray([ 1.0 if er <=75.0 else 0.0 for er in error]))/error.shape[0])\n",
    "\n",
    "    mean_acc = (acc_1 + acc_2 + acc_3 + acc_4 + acc_5 + acc_6)/6\n",
    "    return acc_1, acc_2, acc_3, acc_4, acc_5, acc_6, mean_acc   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11d286ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Make predictions from images\n",
    "def make_predictions(all_image_paths,trained_model):\n",
    "    images =[]\n",
    "    #print()\n",
    "    for i in range(len(all_image_paths)):\n",
    "        try: \n",
    "            path = all_image_paths[i]\n",
    "            images.append(np.asarray(Image.open(path)))\n",
    "\n",
    "        except PIL.UnidentifiedImageError:\n",
    "            print(\"Problem!!:\",i)\n",
    "            \n",
    "    images = np.asarray(images)\n",
    "    print(images.shape)\n",
    "    images = np.moveaxis(images,-1,1)\n",
    "    print(\"Loaded {} images, Max = {}, Min = {}\".format(images.shape, np.max(images), np.min(images)))\n",
    "    \n",
    "    BATCH_SIZE = 1\n",
    "    adv_set = DriveDatasetNoLabels(images)\n",
    "\n",
    "    adv_loader = torch.utils.data.DataLoader(dataset=adv_set,\n",
    "                                                   batch_size=BATCH_SIZE,\n",
    "                                                   collate_fn=None,\n",
    "                                                   shuffle=False)\n",
    "\n",
    "    predictions=[]\n",
    "    with torch.no_grad():\n",
    "        for bi, img in enumerate(adv_loader):\n",
    "            inpt = img.to(device)\n",
    "            outputs = trained_model(inpt) # input should be [1, 3, 66, 200]\n",
    "            predictions.append(outputs.data.item())\n",
    "            \n",
    "    print(\"Predicted {} labels\".format(len(predictions)))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b840a0bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b/.local/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted 10000 labels\n",
      "Acc:\n",
      " 1.5= 82.89999999999999%\n",
      " 3.0= 91.64%\n",
      " 7.5= 96.92%\n",
      " 15 = 98.47%\n",
      " 30= 99.18%\n",
      " 75 = 99.77000000000001%\n",
      "Mean Accuracy = 94.81333333333333%\n",
      "Loss: tensor(0.4060)\n"
     ]
    }
   ],
   "source": [
    "txt_data=[]\n",
    "#predictions on clean\n",
    "clean_paths = sorted(glob.glob('/home/b/Desktop/Contrastive/Data/Steering_Angle/test_Data/validation_sets_clean/valHc/*.jpg'), key = name_adv_load)\n",
    "#print(clean_path)\n",
    "predictions_clean = make_predictions(clean_paths, trained_model)\n",
    "acc_1, acc_2, acc_3, acc_4, acc_5, acc_6, mean_acc = accuracy_metrics(ground_truths, predictions_clean)\n",
    "print(\"Acc:\\n 1.5= {}%\\n 3.0= {}%\\n 7.5= {}%\\n 15 = {}%\\n 30= {}%\\n 75 = {}%\\nMean Accuracy = {}%\".format(acc_1, \n",
    "                                                                                                   acc_2,\n",
    "                                                                                                   acc_3,\n",
    "                                                                                                   acc_4,\n",
    "                                                                                                   acc_5,\n",
    "                                                                                                   acc_6,\n",
    "                                                                                                   mean_acc))\n",
    "loss = loss_mse(ground_truths, predictions_clean)\n",
    "print(\"Loss:\", loss)\n",
    "txt_data.append(\"Clean:    \" + \"Acc: \" + str(mean_acc) + \"    Loss:\" + str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67403213",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loss_collect = []\n",
    "# acc_collect =[]\n",
    "\n",
    "# predictions_fgsm_total=[]\n",
    "# for i in range(len(data_folders_fgsm)): \n",
    "#     all_image_paths = sorted(glob.glob(data_folders_fgsm[i]+\"/\"+\"*.jpg\"), key = name_adv_load)\n",
    "#     predictions = make_predictions(all_image_paths, trained_model)\n",
    "#     predictions_fgsm_total.append(predictions)\n",
    "    \n",
    "#     acc_1, acc_2, acc_3, acc_4, acc_5, acc_6, mean_acc = accuracy_metrics(ground_truths, predictions)\n",
    "#     print(\"For {}\\nAcc:\\n 1.5= {}%\\n 3.0= {}%\\n 7.5= {}%\\n 15 = {}%\\n 30= {}%\\n 75 = {}%\\nMean Accuracy = {}%\".format(data_folders_fgsm[i].split('/')[-1],\n",
    "#                                                                                                     acc_1, \n",
    "#                                                                                                    acc_2,\n",
    "#                                                                                                    acc_3,\n",
    "#                                                                                                    acc_4,\n",
    "#                                                                                                    acc_5,\n",
    "#                                                                                                    acc_6,\n",
    "#                                                                                                        mean_acc))\n",
    "#     loss = loss_mse(ground_truths, predictions)\n",
    "#     print(\"Loss:\", loss)\n",
    "#     loss_collect.append(str(round(loss.item(),2)))\n",
    "#     acc_collect.append(str(round(mean_acc,2)))\n",
    "#     txt_data.append(str(data_folders_fgsm[i].split('/')[-1]) + \"    \" + \"Acc: \" + str(mean_acc) + \"    Loss:\" + str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d97c81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(\"& {}\\% /{} & {}\\% /{} & {}\\% /{} & {}\\% /{} & {}\\% /{}\".format(acc_collect[0],\n",
    "#                                                                                 loss_collect[0],\n",
    "#                                                                                 acc_collect[1],\n",
    "#                                                                                 loss_collect[1],\n",
    "#                                                                                 acc_collect[2],\n",
    "#                                                                                 loss_collect[2],\n",
    "#                                                                                 acc_collect[3],\n",
    "#                                                                                 loss_collect[3],\n",
    "#                                                                                 acc_collect[4],\n",
    "#                                                                                 loss_collect[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819d4f93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predictions_fgsm_total = np.array(predictions_fgsm_total)\n",
    "# print(predictions_fgsm_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f884edf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# permutation = np.arange(1100,1600,1)\n",
    "# fig, ax = plt.subplots(figsize=(16,5), dpi =150)\n",
    "# ax.plot(ground_truths[permutation]*15.0) \n",
    "# ax.plot(predictions_fgsm_total[4][permutation]*15.0)\n",
    "# ax.set_ylabel(\"Steering Angle (Degrees)\", fontsize=12)\n",
    "# ax.set_xlabel(\"Time Steps\", fontsize=12)\n",
    "# ax.legend([\"Ground Truths\",\"Predictions on FGSM\" ], fontsize=12)\n",
    "# ax.set_ylim([-100,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e729205f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loss_collect = []\n",
    "# acc_collect =[]\n",
    "\n",
    "# predictions_pgd_total=[]\n",
    "# for i in range(len(data_folders_pgd)): \n",
    "#     all_image_paths = sorted(glob.glob(data_folders_pgd[i]+\"/\"+\"*.jpg\"), key = name_adv_load)\n",
    "#     predictions = make_predictions(all_image_paths, trained_model)\n",
    "#     predictions_pgd_total.append(predictions)\n",
    "    \n",
    "#     acc_1, acc_2, acc_3, acc_4, acc_5, acc_6, mean_acc = accuracy_metrics(ground_truths, predictions)\n",
    "#     print(\"For {}\\nAcc:\\n 1.5= {}%\\n 3.0= {}%\\n 7.5= {}%\\n 15 = {}%\\n 30= {}%\\n 75 = {}%\\nMean Accuracy = {}%\".format(data_folders_pgd[i].split('/')[-1],\n",
    "#                                                                                                     acc_1, \n",
    "#                                                                                                    acc_2,\n",
    "#                                                                                                    acc_3,\n",
    "#                                                                                                    acc_4,\n",
    "#                                                                                                    acc_5,\n",
    "#                                                                                                    acc_6,\n",
    "#                                                                                                    mean_acc))\n",
    "#     loss = loss_mse(ground_truths, predictions)\n",
    "#     print(\"Loss:\", loss)\n",
    "#     loss_collect.append(str(round(loss.item(),2)))\n",
    "#     acc_collect.append(str(round(mean_acc,2)))\n",
    "#     txt_data.append(str(data_folders_pgd[i].split('/')[-1]) + \"    \" + \"Acc: \" + str(mean_acc) + \"    Loss:\" + str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff05f49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(\"& {}\\% /{} & {}\\% /{} & {}\\% /{} & {}\\% /{} & {}\\% /{}\".format(acc_collect[0],\n",
    "#                                                                                 loss_collect[0],\n",
    "#                                                                                 acc_collect[1],\n",
    "#                                                                                 loss_collect[1],\n",
    "#                                                                                 acc_collect[2],\n",
    "#                                                                                 loss_collect[2],\n",
    "#                                                                                 acc_collect[3],\n",
    "#                                                                                 loss_collect[3],\n",
    "#                                                                                 acc_collect[4],\n",
    "#                                                                                 loss_collect[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443a7bc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predictions_pgd_total = np.array(predictions_pgd_total)\n",
    "# print(predictions_pgd_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9727ce1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# permutation = np.arange(900,1600,1)\n",
    "# fig, ax = plt.subplots(figsize=(16,5), dpi =150)\n",
    "# ax.plot(ground_truths[permutation]*15.0) \n",
    "# ax.plot(predictions_pgd_total[4][permutation]*15.0)\n",
    "# ax.set_ylabel(\"Steering Angle (Degrees)\", fontsize=14)\n",
    "# ax.set_xlabel(\"Time Steps\",fontsize=14)\n",
    "# ax.legend([\"Ground Truths\",\"Predictions on FGSM\" ],fontsize=14)\n",
    "# ax.set_ylim([-100,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2794a85",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded (10000, 3, 66, 200) images, Max = 172, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valHc_combined_1_0\n",
      "Acc:\n",
      " 1.5= 83.89999999999999%\n",
      " 3.0= 86.78%\n",
      " 7.5= 91.58%\n",
      " 15 = 94.43%\n",
      " 30= 96.47%\n",
      " 75 = 98.14%\n",
      "Mean Accuracy = 91.88333333333333%\n",
      "Loss: tensor(8.4749)\n",
      "\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valHc_combined_2_0\n",
      "Acc:\n",
      " 1.5= 50.5%\n",
      " 3.0= 59.75%\n",
      " 7.5= 80.66%\n",
      " 15 = 90.68%\n",
      " 30= 95.19999999999999%\n",
      " 75 = 97.67%\n",
      "Mean Accuracy = 79.07666666666667%\n",
      "Loss: tensor(8.3673)\n",
      "\n",
      "Loaded (10000, 3, 66, 200) images, Max = 226, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valHc_combined_3_0\n",
      "Acc:\n",
      " 1.5= 45.59%\n",
      " 3.0= 56.75%\n",
      " 7.5= 80.42%\n",
      " 15 = 90.60000000000001%\n",
      " 30= 95.48%\n",
      " 75 = 97.7%\n",
      "Mean Accuracy = 77.75666666666667%\n",
      "Loss: tensor(8.2444)\n",
      "\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valHc_combined_4_0\n",
      "Acc:\n",
      " 1.5= 30.29%\n",
      " 3.0= 38.42%\n",
      " 7.5= 65.64%\n",
      " 15 = 88.86%\n",
      " 30= 95.21%\n",
      " 75 = 97.67%\n",
      "Mean Accuracy = 69.34833333333334%\n",
      "Loss: tensor(8.4318)\n",
      "\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valHc_combined_5_0\n",
      "Acc:\n",
      " 1.5= 59.98%\n",
      " 3.0= 71.28999999999999%\n",
      " 7.5= 87.01%\n",
      " 15 = 93.16%\n",
      " 30= 96.36%\n",
      " 75 = 97.92999999999999%\n",
      "Mean Accuracy = 84.28833333333333%\n",
      "Loss: tensor(7.2836)\n",
      "\n",
      "Loaded (10000, 3, 66, 200) images, Max = 255, Min = 0\n",
      "Predicted 10000 labels\n",
      "For valHc_combined_6_0\n",
      "Acc:\n",
      " 1.5= 33.269999999999996%\n",
      " 3.0= 42.67%\n",
      " 7.5= 69.54%\n",
      " 15 = 87.86%\n",
      " 30= 94.87%\n",
      " 75 = 97.57000000000001%\n",
      "Mean Accuracy = 70.96333333333334%\n",
      "Loss: tensor(8.4857)\n"
     ]
    }
   ],
   "source": [
    "loss_collect = []\n",
    "acc_collect =[]\n",
    "predictions_combined_total=[]\n",
    "for i in range(len(data_folders_combined)): \n",
    "    all_image_paths = sorted(glob.glob(data_folders_combined[i]+\"/\"+\"*.jpg\"), key = name_adv_load)\n",
    "    predictions = make_predictions(all_image_paths, trained_model)\n",
    "    predictions_combined_total.append(predictions)\n",
    "    \n",
    "    acc_1, acc_2, acc_3, acc_4, acc_5, acc_6, mean_acc = accuracy_metrics(ground_truths, predictions)\n",
    "    print(\"For {}\\nAcc:\\n 1.5= {}%\\n 3.0= {}%\\n 7.5= {}%\\n 15 = {}%\\n 30= {}%\\n 75 = {}%\\nMean Accuracy = {}%\".format(data_folders_combined[i].split('/')[-1],\n",
    "                                                                                                    acc_1, \n",
    "                                                                                                   acc_2,\n",
    "                                                                                                   acc_3,\n",
    "                                                                                                   acc_4,\n",
    "                                                                                                   acc_5,\n",
    "                                                                                                   acc_6,\n",
    "                                                                                                   mean_acc))\n",
    "    loss = loss_mse(ground_truths, predictions)\n",
    "    print(\"Loss:\", loss)\n",
    "    loss_collect.append(str(round(loss.item(),2)))\n",
    "    acc_collect.append(str(round(mean_acc,2)))\n",
    "    txt_data.append(str(data_folders_combined[i].split('/')[-1]) + \"    \" + \"Acc: \" + str(mean_acc) + \"    Loss:\" + str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efc497f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "& 91.88\\% /8.47 & 79.08\\% /8.37 & 77.76\\% /8.24 & 69.35\\% /8.43 & 84.29\\% /7.28 & 70.96\\% /8.49\n"
     ]
    }
   ],
   "source": [
    "print(\"& {}\\% /{} & {}\\% /{} & {}\\% /{} & {}\\% /{} & {}\\% /{} & {}\\% /{}\".format(acc_collect[0],\n",
    "                                                                                loss_collect[0],\n",
    "                                                                                acc_collect[1],\n",
    "                                                                                loss_collect[1],\n",
    "                                                                                acc_collect[2],\n",
    "                                                                                loss_collect[2],\n",
    "                                                                                acc_collect[3],\n",
    "                                                                                loss_collect[3],\n",
    "                                                                                acc_collect[4],\n",
    "                                                                                loss_collect[4],\n",
    "                                                                                acc_collect[5],\n",
    "                                                                                loss_collect[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5047bfe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "destination: axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-4849af04e8ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_folders_unseen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mall_image_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_folders_unseen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"*.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname_adv_load\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_image_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrained_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mpredictions_unseen_total\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-8f3527b4c585>\u001b[0m in \u001b[0;36mmake_predictions\u001b[0;34m(all_image_paths, trained_model)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#print(images.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loaded {} images, Max = {}, Min = {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmoveaxis\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mmoveaxis\u001b[0;34m(a, source, destination)\u001b[0m\n\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_axis_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'source'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m     \u001b[0mdestination\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_axis_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'destination'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1430\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m         raise ValueError('`source` and `destination` arguments must have '\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mnormalize_axis_tuple\u001b[0;34m(axis, ndim, argname, allow_duplicate)\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;31m# Going via an iterator directly is slower than via list comprehension.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1358\u001b[0;31m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnormalize_axis_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1359\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicate\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;31m# Going via an iterator directly is slower than via list comprehension.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1358\u001b[0;31m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnormalize_axis_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1359\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicate\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAxisError\u001b[0m: destination: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "loss_collect = []\n",
    "acc_collect =[]\n",
    "predictions_unseen_total=[]\n",
    "for i in range(len(data_folders_unseen)): \n",
    "    all_image_paths = sorted(glob.glob(data_folders_unseen[i]+\"/\"+\"*.jpg\"), key = name_adv_load)\n",
    "    predictions = make_predictions(all_image_paths, trained_model)\n",
    "    predictions_unseen_total.append(predictions)\n",
    "    \n",
    "    acc_1, acc_2, acc_3, acc_4, acc_5, acc_6, mean_acc = accuracy_metrics(ground_truths, predictions)\n",
    "    print(\"For {}\\nAcc:\\n 1.5= {}%\\n 3.0= {}%\\n 7.5= {}%\\n 15 = {}%\\n 30= {}%\\n 75 = {}%\\nMean Accuracy = {}%\".format(data_folders_unseen[i].split('/')[-1],\n",
    "                                                                                                    acc_1, \n",
    "                                                                                                   acc_2,\n",
    "                                                                                                   acc_3,\n",
    "                                                                                                   acc_4,\n",
    "                                                                                                   acc_5,\n",
    "                                                                                                   acc_6,\n",
    "                                                                                                   mean_acc))\n",
    "    loss = loss_mse(ground_truths, predictions)\n",
    "    print(\"Loss:\", loss)\n",
    "    loss_collect.append(str(round(loss.item(),2)))\n",
    "    acc_collect.append(str(round(mean_acc,2)))\n",
    "    txt_data.append(str(data_folders_unseen[i].split('/')[-1]) + \"    \" + \"Acc: \" + str(mean_acc) + \"    Loss:\" + str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26708b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for j in range(1,len(data_folders_unseen)+1):\n",
    "    if j%5==0:\n",
    "        \n",
    "        print(j-5, j-4, j-3, j-2, j-1)\n",
    "        print(j)\n",
    "#         print(data_folders_unseen[j])\n",
    "        print(\"& {}\\% /{} & {}\\% /{} & {}\\% /{} & {}\\% /{} & {}\\% /{}\\n\".format(acc_collect[j-5],\n",
    "                                                                                        loss_collect[j-5],\n",
    "                                                                                        acc_collect[j-4],\n",
    "                                                                                        loss_collect[j-4],\n",
    "                                                                                        acc_collect[j-3],\n",
    "                                                                                        loss_collect[j-3],\n",
    "                                                                                        acc_collect[j-2],\n",
    "                                                                                        loss_collect[j-2],\n",
    "                                                                                        acc_collect[j-1],\n",
    "                                                                                        loss_collect[j-1]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9c8b4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(data_folders_unseen))\n",
    "print(data_folders_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4cfb0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fname= \"/home/b/Desktop/week_3_experiments/results/\" + path.split('/')[-1] + \"_results.txt\"\n",
    "# np.savetxt(fname, txt_data, fmt='%s', newline='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a988c8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852ca748",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
